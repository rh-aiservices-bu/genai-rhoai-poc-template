{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3420575b-4d00-458b-aa0e-7030008ccd53",
   "metadata": {},
   "source": [
    "## Creating an index and populating it with documents using Elasticsearch\n",
    "\n",
    "Simple example on how to ingest PDF documents, then web pages content into an Elasticsearch VectorStore.\n",
    "\n",
    "Requirements:\n",
    "- An Elasticsearch cluster \n",
    "    - Can be done using ElasticSearch operator\n",
    "    - Create an ElasticSearch Cluster instance from the operator\n",
    "    - This will create the required certs and credentials for connecting\n",
    "    \n",
    "__NOTE: You will need the correct certs in order to establish a connection with the Elasticsearch pod. It might be helpful to use an SSL Cert decoder to decode the `tls.crt` and the `ca.crt` to ensure that the service URL is whitelisted.__\n",
    "\n",
    "## ElasticSearch Install and Config\n",
    "\n",
    "## Install and Configuration\n",
    "\n",
    "1. Install Elasticsearch (ECK) Operator from Operator Hub or through ArgoCD\n",
    "2. Create an Elasticsearch Cluster Resource using the form or a YAML\n",
    "\n",
    "```yaml\n",
    "kind: Elasticsearch\n",
    "apiVersion: elasticsearch.k8s.elastic.co/v1\n",
    "metadata:\n",
    "  name: elasticsearch # or any name you want\n",
    "  namespace: <NAMESPACE> # CHANGE\n",
    "spec:\n",
    "  version: 8.14.0\n",
    "  nodeSets:\n",
    "    - name: default\n",
    "      config:\n",
    "        node.roles:\n",
    "          - master\n",
    "          - data\n",
    "        node.attr.attr_name: attr_value\n",
    "        node.store.allow_mmap: false\n",
    "      podTemplate:\n",
    "        metadata:\n",
    "          labels: # Configure as necessary\n",
    "            <ADD LABELS HERE>\n",
    "        spec:\n",
    "          containers:\n",
    "            - name: elasticsearch\n",
    "              resources: <CHANGE MEMORY REQUESTS> # Configure as necessary\n",
    "                requests:\n",
    "                  memory: 4Gi\n",
    "                  cpu: 1\n",
    "                limits:\n",
    "                  memory: 4Gi\n",
    "                  cpu: 2\n",
    "      count: <POD REPLICAS>\n",
    "\n",
    "```\n",
    "3. Once this yaml has been created and deployed the following resources will also be created\n",
    "    * elasticsearch-es-default\n",
    "    * elasticsearch-es-default-es-config\n",
    "    * elasticsearch-es-default-es-transport-certs\n",
    "    * elasticsearch-es-file-settings\n",
    "    * elasticsearch-es-http\n",
    "    * elasticsearch-es-http-ca-internal\n",
    "    * elasticsearch-es-http-certs-internal\n",
    "    * elasticsearch-es-internal-http\n",
    "    * elasticsearch-es-internal-users\n",
    "    * elasticsearch-es-remote-ca\n",
    "    * elasticsearch-es-scripts\n",
    "    * elasticsearch-es-transport\n",
    "    * elasticsearch-es-transport-ca-internal\n",
    "    * elasticsearch-es-unicast-hosts\n",
    "    * elasticsearch-es-xpack-file-realm\n",
    "\n",
    "4. The resources that we will need to connect and query the elastic DB are:\n",
    "    * elasticsearch-es-http (svc)\n",
    "    * elasticsearch-es-internal-http (svc)\n",
    "    * elasticsearch-es-http-certs-internal (secret)\n",
    "    * elasticsearch-es-internal-users (secret)\n",
    "\n",
    "5. Inside this notebook:\n",
    "    - HOST =  elasticsearch-es-http\n",
    "    - PORT = 9200\n",
    "    - Create create/update ca.crt file to have the contents of the ca.crt field of the secret `elasticsearch-es-http-certs-internal` \n",
    "\n",
    "### (Optional) Creating a Route\n",
    "1. Go to OCP Web Console > Networking > Routes\n",
    "2. Create a route that points to the service `elasticsearch-es-http`\n",
    "3. Check TLS encrypted\n",
    "4. Set the encryption type to Reencrypt\n",
    "5. Set the `Destination CA Cert` to the value of the ca.crt field of the secret `elasticsearch-es-http-certs-internal`\n",
    "6. Visit the route, you will need to use the username `elastic` and password from the secret `elasticsearch-es-internal-users`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308b229-b520-4e82-a783-eb921bb955e7",
   "metadata": {},
   "source": [
    "### Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e41b41-f60a-4b0f-91a1-cd273b60f21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q elasticsearch langchain==0.1.12 pypdf==4.0.2 sentence-transformers==2.4.0 einops==0.7.0 lxml==5.1.0 tqdm==4.66.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82063d-6153-4812-8977-042241736b53",
   "metadata": {},
   "source": [
    "### Base parameters, the Elasticsearch info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ed4a4-9418-4f48-bebd-ef0ea11ae434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ELASTIC_USER = \"elastic\"\n",
    "ELASTIC_PASSWORD = os.getenv(\"ELASTIC_PASSWORD\")\n",
    "HOST = 'elasticsearch-es-http.rhsaia-lab.svc'\n",
    "PORT = '9200'\n",
    "\n",
    "product_version = 2.9\n",
    "COLLECTION_NAME = f\"rhoai-doc-{product_version}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b499a49-128c-4be5-903b-76c40771c7bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600cd763-6ecc-4c77-89c0-47108c31c44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import ElasticsearchStore\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed9b75-b520-44c6-a29f-16829a93cd72",
   "metadata": {},
   "source": [
    "#### Create Elasticsearch Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c81a1-7c94-453f-9f09-eabbf7fd148d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es_conn = Elasticsearch(\n",
    "    f\"https://{HOST}:{PORT}\",\n",
    "    basic_auth=(ELASTIC_USER, ELASTIC_PASSWORD),\n",
    "    ca_certs=\"ca.crt\"\n",
    ")\n",
    "es_conn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f6785-480e-4519-be4f-8e1738dba4ca",
   "metadata": {},
   "source": [
    "## Initial index creation and document ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cff5f7-c509-48db-90b5-e15815b8b530",
   "metadata": {},
   "source": [
    "#### Download and load pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fe0db-f494-4cbd-9e97-8b6359a78cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"release_notes\",\n",
    "    \"introduction_to_red_hat_openshift_ai\",\n",
    "    \"getting_started_with_red_hat_openshift_ai_self-managed\",\n",
    "    \"openshift_ai_tutorial_-_fraud_detection_example\",\n",
    "    \"developing_a_model\",\n",
    "    \"integrating_data_from_amazon_s3\",\n",
    "    \"working_on_data_science_projects\",\n",
    "    \"serving_models\",\n",
    "    \"monitoring_data_science_models\",\n",
    "    \"managing_users\",\n",
    "    \"managing_resources\",\n",
    "    \"installing_and_uninstalling_openshift_ai_self-managed\",\n",
    "    \"installing_and_uninstalling_openshift_ai_self-managed_in_a_disconnected_environment\",\n",
    "    \"upgrading_openshift_ai_self-managed\",\n",
    "    \"upgrading_openshift_ai_self-managed_in_a_disconnected_environment\",   \n",
    "]\n",
    "\n",
    "pdfs = [f\"https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/{product_version}/pdf/{doc}/red_hat_openshift_ai_self-managed-{product_version}-{doc}-en-us.pdf\" for doc in documents]\n",
    "pdfs_to_urls = {f\"red_hat_openshift_ai_self-managed-{product_version}-{doc}-en-us\": f\"https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/{product_version}/html-single/{doc}/index\" for doc in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea5acc-49df-41c9-a01a-0cdbca96e8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "docs_dir = f\"rhoai-doc-{product_version}\"\n",
    "\n",
    "if not os.path.exists(docs_dir):\n",
    "    os.mkdir(docs_dir)\n",
    "\n",
    "for pdf in pdfs:\n",
    "    try:\n",
    "        response = requests.get(pdf)\n",
    "    except:\n",
    "        print(f\"Skipped {pdf}\")\n",
    "        continue\n",
    "    if response.status_code!=200:\n",
    "        print(f\"Skipped {pdf}\")\n",
    "        continue  \n",
    "    with open(f\"{docs_dir}/{pdf.split('/')[-1]}\", 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4074d4-eff4-45b2-902d-ec8c075a83ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_folder_path = f\"./rhoai-doc-{product_version}\"\n",
    "\n",
    "pdf_loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "pdf_docs = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7ed3a-0530-47a1-95c2-22db6c782a95",
   "metadata": {},
   "source": [
    "#### Inject metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702230f6-e6d3-44c7-a643-4996387606ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for doc in pdf_docs:\n",
    "    doc.metadata[\"source\"] = pdfs_to_urls[Path(doc.metadata[\"source\"]).stem]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd511d44-2d92-47a0-9163-b25576c9557b",
   "metadata": {},
   "source": [
    "#### Load websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebf003-d7ec-43ba-8e04-1931bcff2866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "websites = [\n",
    "    \"https://ai-on-openshift.io/getting-started/openshift/\",\n",
    "    \"https://ai-on-openshift.io/getting-started/opendatahub/\",\n",
    "    \"https://ai-on-openshift.io/getting-started/openshift-ai/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/configuration/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/custom-notebooks/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/nvidia-gpus/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/custom-runtime-triton/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/openshift-group-management/\",\n",
    "    \"https://ai-on-openshift.io/tools-and-applications/minio/minio/\",\n",
    "    \"https://access.redhat.com/articles/7047935\",\n",
    "    \"https://access.redhat.com/articles/rhoai-supported-configs\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f41110-8ca7-4d90-93b2-3b5021c894b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "website_loader = WebBaseLoader(websites)\n",
    "website_docs = website_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ddd29-54b3-474a-9b10-2d274bc3254f",
   "metadata": {},
   "source": [
    "#### Merge both types of docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d361094-8b43-4351-8495-37628c35c42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = pdf_docs + website_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198fe0a-38bf-4cd4-af7d-35b41c645edd",
   "metadata": {},
   "source": [
    "#### Split documents into chunks with some overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba4a08-2194-4df1-9091-6f2b596757a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024,\n",
    "                                               chunk_overlap=40)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884f070",
   "metadata": {},
   "source": [
    "#### Cleanup documents as PostgreSQL won't accept the NUL character, '\\x00', in TEXT fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aefc08d-a4ad-4aad-9120-cfa98b67cbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in all_splits:\n",
    "    doc.page_content = doc.page_content.replace('\\x00', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7eae2-c670-4eb5-803b-b4d591fa83db",
   "metadata": {},
   "source": [
    "#### Create the index and ingest the documents (Method #1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To ingest with GPUs\n",
    "model_kwargs = {\"trust_remote_code\": True, \"device\": \"cuda\"}\n",
    "\n",
    "# Define embedding model\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Instantiate langchain vectorstore and ingest from documents\n",
    "db = ElasticsearchStore.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    index_name=COLLECTION_NAME,\n",
    "    es_connection=es_conn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d987b-8ebc-46ce-a206-48c1339b7a5b",
   "metadata": {},
   "source": [
    "#### Alternatively, add new documents (Method #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f227d-a13d-456c-b91b-3c203e62fc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs = {\"trust_remote_code\": True, \"device\": \"cuda\"}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Instantiate langchain vectorstore\n",
    "db = ElasticsearchStore(\n",
    "    embedding=embeddings,\n",
    "    index_name=COLLECTION_NAME,\n",
    "    es_connection=es_conn\n",
    ")\n",
    "\n",
    "# Add docs\n",
    "db.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3b458-4979-46df-8493-7496764a2568",
   "metadata": {},
   "source": [
    "#### Test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c6e6d-c42c-4de4-87cf-8edfd0e63da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How can I work with GPU and taints in OpenShift AI?\"\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90feeb37-7888-4c5f-a5cb-5f82637cec16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbb964-83aa-4f5d-805c-11d849d8cbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
